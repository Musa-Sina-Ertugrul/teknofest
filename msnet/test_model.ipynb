{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Model,DataSet\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from torchmetrics import Accuracy,F1Score\n",
    "from torchmetrics.classification import BinaryAccuracy\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from zemberek import TurkishTokenizer\n",
    "from torchnlp.encoders.text import StaticTokenizerEncoder, stack_and_pad_tensors, pad_tensor\n",
    "import sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-turkish-cased\")\n",
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {'train': 'train.csv', 'test': 'test.csv'}\n",
    "df_train = pd.read_csv(\"hf://datasets/winvoker/turkish-sentiment-analysis-dataset/\" + splits[\"train\"])\n",
    "df_test = pd.read_csv(\"hf://datasets/winvoker/turkish-sentiment-analysis-dataset/\" + splits[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pos = df_train[df_train[\"label\"]==\"Positive\"].sample(50905,random_state=42)\n",
    "df_train_neg = df_train[df_train[\"label\"]==\"Negative\"].sample(50905,random_state=42)\n",
    "df_train_notr = df_train[df_train[\"label\"]==\"Notr\"].sample(50905,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33593/431224704.py:5: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Notr' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_yasemin_notr[df_yasemin_notr[\"label\"]==1] = \"Notr\"\n",
      "/tmp/ipykernel_33593/431224704.py:6: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Negative' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_yasemin_neg[df_yasemin_neg[\"label\"]==2] = \"Negative\"\n",
      "/tmp/ipykernel_33593/431224704.py:7: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Positive' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_yasemin_pos[df_yasemin_pos[\"label\"]==3] = \"Positive\"\n"
     ]
    }
   ],
   "source": [
    "df_yasemin = pd.read_csv(\"/home/musasina/projects/teknofest/msnet/datasets/yasemin_data.csv\")\n",
    "df_yasemin_notr = df_yasemin[df_yasemin[\"label\"]==1].sample(7328,random_state=42)\n",
    "df_yasemin_neg = df_yasemin[df_yasemin[\"label\"]==2].sample(7328,random_state=42)\n",
    "df_yasemin_pos = df_yasemin[df_yasemin[\"label\"]==3].sample(7328,random_state=42)\n",
    "df_yasemin_notr[df_yasemin_notr[\"label\"]==1] = \"Notr\"\n",
    "df_yasemin_neg[df_yasemin_neg[\"label\"]==2] = \"Negative\"\n",
    "df_yasemin_pos[df_yasemin_pos[\"label\"]==3] = \"Positive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>333718</th>\n",
       "      <td>Bazı eşyalar ise kendisine en diplomatik biçim...</td>\n",
       "      <td>Notr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70701</th>\n",
       "      <td>Daha önce de birlikte çalıştıkları olmuştu .</td>\n",
       "      <td>Notr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230605</th>\n",
       "      <td>Hayatı ve eserleri hakkında pek fazla bilgi yo...</td>\n",
       "      <td>Notr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299837</th>\n",
       "      <td>Mahallenin adı Türkmenlerin Yuva boyundan gelm...</td>\n",
       "      <td>Notr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22537</th>\n",
       "      <td>Her turnuvanın altında parantez içinde yer ala...</td>\n",
       "      <td>Notr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273267</th>\n",
       "      <td>Bu öncül bileşikler temiz ve ucuz bir şekilde ...</td>\n",
       "      <td>Notr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1327</th>\n",
       "      <td>Piyanoda üstün yetenekli bir çocuktu .</td>\n",
       "      <td>Notr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67996</th>\n",
       "      <td>Belediye Birinci Aral ve İkinci Aral köylerind...</td>\n",
       "      <td>Notr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383315</th>\n",
       "      <td>İki alt türü bulunur .</td>\n",
       "      <td>Notr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211633</th>\n",
       "      <td>Albüm müzik eleştirmenlerinin beğenisini kazan...</td>\n",
       "      <td>Notr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50905 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text label\n",
       "333718  Bazı eşyalar ise kendisine en diplomatik biçim...  Notr\n",
       "70701        Daha önce de birlikte çalıştıkları olmuştu .  Notr\n",
       "230605  Hayatı ve eserleri hakkında pek fazla bilgi yo...  Notr\n",
       "299837  Mahallenin adı Türkmenlerin Yuva boyundan gelm...  Notr\n",
       "22537   Her turnuvanın altında parantez içinde yer ala...  Notr\n",
       "...                                                   ...   ...\n",
       "273267  Bu öncül bileşikler temiz ve ucuz bir şekilde ...  Notr\n",
       "1327               Piyanoda üstün yetenekli bir çocuktu .  Notr\n",
       "67996   Belediye Birinci Aral ve İkinci Aral köylerind...  Notr\n",
       "383315                             İki alt türü bulunur .  Notr\n",
       "211633  Albüm müzik eleştirmenlerinin beğenisini kazan...  Notr\n",
       "\n",
       "[50905 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_pos.drop(\"dataset\",axis=1)\n",
    "df_train_neg.drop(\"dataset\",axis=1)\n",
    "df_train_notr.drop(\"dataset\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing\n",
    "import sklearn.utils\n",
    "\n",
    "\n",
    "df_train = sklearn.utils.shuffle(pd.concat((df_train_pos,df_train_neg,df_train_notr,df_yasemin_notr,df_yasemin_neg,df_yasemin_pos),ignore_index=True),random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(examples):\n",
    "    model_inputs = tokenizer(examples, max_length=128,padding=\"max_length\",truncation=True,return_tensors=\"pt\")\n",
    "    return np.array(model_inputs[\"input_ids\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = df_train[\"text\"].map(preprocess).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(df_train[\"label\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Negative', 'Notr', 'Positive'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "encoded_labels = []\n",
    "factorized = pd.factorize(df_train[\"label\"],sort=True)\n",
    "print(factorized[1])\n",
    "train_label = F.one_hot(torch.tensor(factorized[0],dtype=torch.long),num_classes=3).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = torch.Tensor(np.array(encoded_text))\n",
    "train_text = train_text.type(dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"text\"] = df_test[\"text\"].convert_dtypes(convert_string=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(examples):\n",
    "    model_inputs = tokenizer(examples, max_length=128,padding=\"max_length\",truncation=True,return_tensors=\"pt\")\n",
    "    return np.array(model_inputs[\"input_ids\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = df_test[\"text\"].map(preprocess).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(df_test[\"label\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Negative', 'Notr', 'Positive'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "encoded_labels = []\n",
    "factorized = pd.factorize(df_test[\"label\"],sort=True)\n",
    "print(factorized[1])\n",
    "test_label = F.one_hot(torch.tensor(factorized[0],dtype=torch.long),num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = torch.Tensor(np.array(encoded_text))\n",
    "test_text = test_text.type(dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                                            Param #\n",
       "==========================================================================================\n",
       "Model                                                             --\n",
       "├─MFP: 1-1                                                        --\n",
       "│    └─LeakyReLU: 2-1                                             --\n",
       "│    └─ReLU: 2-2                                                  --\n",
       "│    └─Sigmoid: 2-3                                               --\n",
       "│    └─Tanh: 2-4                                                  --\n",
       "│    └─Mish: 2-5                                                  --\n",
       "│    └─SiLU: 2-6                                                  --\n",
       "│    └─SELU: 2-7                                                  --\n",
       "│    └─ELU: 2-8                                                   --\n",
       "│    └─GELU: 2-9                                                  --\n",
       "│    └─Softplus: 2-10                                             --\n",
       "│    └─Linear: 2-11                                               983,808\n",
       "│    └─Linear: 2-12                                               983,808\n",
       "│    └─Linear: 2-13                                               983,808\n",
       "│    └─Linear: 2-14                                               983,808\n",
       "│    └─Linear: 2-15                                               983,808\n",
       "│    └─Linear: 2-16                                               983,808\n",
       "│    └─Linear: 2-17                                               983,808\n",
       "│    └─Linear: 2-18                                               983,808\n",
       "│    └─KAN: 2-19                                                  --\n",
       "│    │    └─ModuleList: 3-1                                       42,467,328\n",
       "│    └─Linear: 2-20                                               25,169,920\n",
       "│    └─Linear: 2-21                                               6,292,992\n",
       "│    └─Linear: 2-22                                               7,690\n",
       "│    └─Linear: 2-23                                               1,967,360\n",
       "│    └─Linear: 2-24                                               3,843\n",
       "│    └─LayerNorm: 2-25                                            1,536\n",
       "│    └─LayerNorm: 2-26                                            12,288\n",
       "│    └─Dropout1d: 2-27                                            --\n",
       "│    └─Softmax: 2-28                                              --\n",
       "│    └─Flatten: 2-29                                              --\n",
       "├─BertLMHeadModel: 1-2                                            --\n",
       "│    └─BertModel: 2-30                                            --\n",
       "│    │    └─BertEmbeddings: 3-2                                   24,972,288\n",
       "│    │    └─BertEncoder: 3-3                                      85,054,464\n",
       "│    └─BertOnlyMLMHead: 2-31                                      --\n",
       "│    │    └─BertLMPredictionHead: 3-4                             624,128\n",
       "==========================================================================================\n",
       "Total params: 194,444,301\n",
       "Trainable params: 194,444,301\n",
       "Non-trainable params: 0\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model().to(\"cuda\")\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DataSet(train_text,train_label)\n",
    "test_dataset = DataSet(test_text,test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=train_dataset,shuffle=True,batch_size=128)\n",
    "test_dataloader = DataLoader(dataset=test_dataset,shuffle=False,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimezer = torch.optim.AdamW(model.parameters(),lr=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.LinearLR(optimizer=optimezer,end_factor=1e-8,total_iters=25)\n",
    "loss = torch.nn.CrossEntropyLoss().to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = Accuracy(\"multilabel\",num_labels=3).to(\"cuda\")\n",
    "f1 = F1Score(\"multilabel\",num_labels=3).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = SummaryWriter(\"./log\",comment=\"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spell funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-02 06:41:10,864 - zemberek.morphology.turkish_morphology - INFO\n",
      "Msg: TurkishMorphology instance initialized in 2.029987096786499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "from zemberek import (\n",
    "    TurkishSentenceNormalizer,\n",
    "    TurkishSentenceExtractor,\n",
    "    TurkishMorphology,\n",
    "    TurkishSpellChecker,\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "morphology = TurkishMorphology.create_with_defaults()\n",
    "normalizer = TurkishSentenceNormalizer(morphology)\n",
    "extractor = TurkishSentenceExtractor()\n",
    "spell_checker = TurkishSpellChecker(morphology)\n",
    "\n",
    "def correct_spells(text: str):\n",
    "\n",
    "    words = text.split(\" \")\n",
    "    for i, word in enumerate(words):\n",
    "        try:\n",
    "            words[i] = spell_checker.suggest_for_word(word)[0]\n",
    "        except BaseException:\n",
    "            continue\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_long_text(paragraph: str) -> str:\n",
    "    result = []\n",
    "    for sentence in paragraph:\n",
    "        try:\n",
    "            result.append(normalizer.normalize(sentence))\n",
    "        except BaseException:\n",
    "            continue\n",
    "    return \" \".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/musasina/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "stops = set(stopwords.words(\"turkish\"))\n",
    "\n",
    "def clear_stop_words(sentence):\n",
    "    return [word for word in sentence.split(\" \") if word not in stops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zeyrek\n",
    "\n",
    "analyzer = zeyrek.MorphAnalyzer()\n",
    "\n",
    "def lemmatize_sent(text):\n",
    "    result = []\n",
    "    for word in text:\n",
    "        try:\n",
    "            result.append(analyzer.lemmatize(word)[0][1][0])\n",
    "        except BaseException:\n",
    "            result.append(word)\n",
    "    return \" \".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_sentence(text:str):\n",
    "    text = text.casefold()\n",
    "    text = correct_spells(text)\n",
    "    text = normalize_long_text(text)\n",
    "    text = clear_stop_words(text)\n",
    "    text = lemmatize_sent(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25ba702e047f432eb6049a2bbbf3b1e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc231eac0ac24cf7ab4bed7a2dfdfbba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "started testing ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b365e119774207861f15bd34309968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/383 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc ->  0.9572348862341739\n",
      "test f1 ->  0.9358453310189608\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35ef8005f4be4d1ead86b0b0be11a80b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "started testing ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa008d3a316c44c9858857ea8604cff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/383 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc ->  0.9683527783065179\n",
      "test f1 ->  0.9525267267040421\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7927272b5c142f8aa0a5ed11a26bffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "started testing ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adabc35312aa4f9ab39b205db3b2fc0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/383 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc ->  0.9653717863030595\n",
      "test f1 ->  0.9480514408091653\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd431923a9754e4ab42dd7483dfef8a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "started testing ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "881fe834b0b4465faa416fd456c40e4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/383 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc ->  0.9661012919079853\n",
      "test f1 ->  0.9491504587952836\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d12c0ba1d42f49bda95ee6f975db83e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "started testing ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efea90a1265247ef81bf882966c36958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/383 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc ->  0.9659497339482719\n",
      "test f1 ->  0.9489230426422298\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "658c33e1dc524c8988c65cee24daa7a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "started testing ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4018ea3a0940485f9e330e65caf5f45f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/383 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc ->  0.9684859081596991\n",
      "test f1 ->  0.9527279817093135\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8d8ab4af9dc4b02b2d7221674f6f3c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "started testing ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d17007a39c94806b8099aac185a724b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/383 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc ->  0.9700662243148366\n",
      "test f1 ->  0.9550991361819733\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "556415ae5a9847879981bf7fe61dd6b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "started testing ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "827385e3fc324249b17be7e9fc98e0b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/383 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc ->  0.9704605896541406\n",
      "test f1 ->  0.9556898832632419\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd22125bf5d74fbc8838c1da567fe2e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "started testing ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c892589f66448599c2f60249f98c8f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/383 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc ->  0.9717816408558241\n",
      "test f1 ->  0.9576721021774233\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cd57cc5f1cc4a7e989caa62264af70e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "started testing ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b55d42545674c928920f2ac0798c8e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/383 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc ->  0.9718340643080968\n",
      "test f1 ->  0.9577506586092259\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99cee263da0b41ba920e9d4368092a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "started testing ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe641f0216e4c3aaa074babc720be6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/383 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc ->  0.9719816808912213\n",
      "test f1 ->  0.9579708023731142\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df1d6beb2aea4beda86871627d4256ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "started testing ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e243318cc5c4b5ebb7c195ad6f9c406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/383 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc ->  0.9730083877050534\n",
      "test f1 ->  0.9595117842870966\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "323d83c62cf243c8952f8180b86f3eff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "started testing ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41bb451782574f458924fdadee4695aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/383 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc ->  0.9717864699214308\n",
      "test f1 ->  0.9576792250102867\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffddf8faaef042b1841c12c8336c9a3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "started testing ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6d4d0a75e7e47b382d56b2673c43523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/383 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc ->  0.9752181931824347\n",
      "test f1 ->  0.9628268472519618\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a6d2af44a49433ebb969dced9c0bbe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "started testing ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0df7f16f21148829ed03ce1c2b7ade8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/383 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc ->  0.9738311160637878\n",
      "test f1 ->  0.9607462336749383\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64a4c717b5b14746a5885960a199cfd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "started testing ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0407585156b46229bc5ad5d69749408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/383 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc ->  0.975014210525443\n",
      "test f1 ->  0.9625210346503296\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df2be0b7a11d4369aed114a0efae84c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "started testing ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98c58e7cdc4e4fd7b468edb161013f7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/383 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc ->  0.975476569357491\n",
      "test f1 ->  0.9632145725093374\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ae8b1fc6d404911a43db4dac9eb1c93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "started testing ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5127a0c4a734425a91c56d22da983ff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/383 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc ->  0.9725208064594717\n",
      "test f1 ->  0.9587789665003047\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90b216cae4f14005a583abc700f3ba68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "started testing ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a259e51360dd48b794a06c048ea0af0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/383 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc ->  0.9721516655568354\n",
      "test f1 ->  0.9582274993468203\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41df5e4692dd4db78c1f8ede7dc44495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "started testing ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "262dc98642bf40adb06d4e6db1e85ab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/383 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc ->  0.9747762323670848\n",
      "test f1 ->  0.9621634666975734\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f5f84b827c4a60a0345245b5402ae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "started testing ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69cf97147cc14ac88c28d38217a96115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/383 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc ->  0.9734571502974388\n",
      "test f1 ->  0.9601849239737807\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1beebdbeebdc4412b6fd055dfaf4e4e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "started testing ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7321e4c6665545deb70bce201d07cf9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/383 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc ->  0.973797119784293\n",
      "test f1 ->  0.9606956781979952\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b11bd84be5c84557ab71ca052dee85ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "started testing ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8fe400f8eed4b6194e690777d775bcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/383 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc ->  0.974014699925953\n",
      "test f1 ->  0.9610220489551753\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc9567c828904c26a5d0aa8134cb753b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "started testing ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e079d9199c475384919b9a26993ee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/383 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc ->  0.9738923108920104\n",
      "test f1 ->  0.9608384654042615\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ee0cb5bf9cc47e4878ac26a3b31c96b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n",
      "started testing ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce61d1222464177a1bf5e76163d310e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/383 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc ->  0.9735863379959027\n",
      "test f1 ->  0.9603791465647227\n"
     ]
    }
   ],
   "source": [
    "past_acc = 0\n",
    "for epoch in tqdm(range(0,25)):\n",
    "    for i,(x,y) in enumerate(tqdm(train_dataloader)):\n",
    "        model.train()\n",
    "        y = y.to(\"cuda\")\n",
    "        final = model(x)\n",
    "        losses = loss(final,y)\n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "            tensorboard.add_scalar(tag=\"loss\",scalar_value=losses.cpu().item(),global_step=(epoch*len(train_dataloader))+i)\n",
    "        model.train()\n",
    "        optimezer.zero_grad()\n",
    "        losses.backward()\n",
    "        #[loss_back.backward(retain_graph=True) for loss_back in losses]\n",
    "        #torch.nn.utils.clip_grad_norm_(model.parameters(),1.0,error_if_nonfinite=True)\n",
    "        optimezer.step()\n",
    "        if (i+1)%100 == 0:\n",
    "            model.eval()\n",
    "            with torch.inference_mode():\n",
    "                text = \"turkcell müşteri hizmetlerinden istediğim verimi aldım\"\n",
    "                tokens = tokenizer([text], max_length=128,padding=\"max_length\",truncation=True,return_tensors=\"pt\")[\"input_ids\"]\n",
    "                print(model(tokens).argmax(dim=1))\n",
    "    scheduler.step()\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        results_acc = []\n",
    "        results_f1 = []\n",
    "        print(\"started testing ...\")\n",
    "        for i,(x,y) in enumerate(tqdm(test_dataloader)):\n",
    "            y = y.to(\"cuda\")\n",
    "            result = model(x)\n",
    "            results_acc.append(acc(result,y).cpu().item())\n",
    "            results_f1.append(f1(result,y).cpu().item())\n",
    "        print(\"test acc -> \", np.mean(results_acc))\n",
    "        print(\"test f1 -> \", np.mean(results_f1))\n",
    "    if past_acc < np.mean(results_acc):\n",
    "        torch.save({\"model_state_dict\":model.state_dict(),\n",
    "                \"optimezer_state_dict\": optimezer.state_dict(),\n",
    "                \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "                \"loss\": loss.state_dict(),\n",
    "                \"epoch\":epoch},\"./model.pth\")\n",
    "        past_acc = np.mean(results_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x80 and 1280x768)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mturkcell müşteri hizmetlerinden istediğim verimi aldım\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m tokens \u001b[38;5;241m=\u001b[39m tokenizer([text], max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m,truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/teknofest/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/teknofest/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/teknofest/msnet/model.py:227\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, input_ids)\u001b[0m\n\u001b[1;32m    225\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m    226\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(input_ids)\u001b[38;5;241m.\u001b[39mlogits\n\u001b[0;32m--> 227\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmfp\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/anaconda3/envs/teknofest/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/teknofest/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/teknofest/msnet/model.py:153\u001b[0m, in \u001b[0;36mMFP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    151\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_start_1(x))\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m#-------------------------------------------\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m x_leaky_relu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleaky_relu_linear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m x_leaky_relu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleaky_relu(x_leaky_relu)\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# ------------------------------------------\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/teknofest/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/teknofest/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/teknofest/lib/python3.11/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x80 and 1280x768)"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    text = \"turkcell müşteri hizmetlerinden istediğim verimi aldım\"\n",
    "    tokens = tokenizer([text], max_length=8,padding=\"max_length\",truncation=True,return_tensors=\"pt\")[\"input_ids\"]\n",
    "    print(model(tokens).argmax(dim=2).view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started testing ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "861a1c285f6a42a6a99586a6488042f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc ->  0.27889183438112347\n",
      "test f1 ->  0.40866448055492904\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    results_acc = []\n",
    "    results_f1 = []\n",
    "    print(\"started testing ...\")\n",
    "    for i,(x,y) in enumerate(tqdm(test_dataloader)):\n",
    "        y = y.to(\"cuda\")\n",
    "        results = model(x)\n",
    "        for result,inner_y in zip(results,y):\n",
    "            results_acc.append(acc(result,inner_y).cpu().item())\n",
    "            results_f1.append(f1(result,inner_y).cpu().item())\n",
    "    print(\"test acc -> \", np.mean(results_acc))\n",
    "    print(\"test f1 -> \", np.mean(results_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadded = torch.load(\"./model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(loadded[\"model_state_dict\"])\n",
    "optimezer.load_state_dict(loadded['optimezer_state_dict'])\n",
    "scheduler.load_state_dict(loadded[\"scheduler_state_dict\"])\n",
    "loss.load_state_dict(loadded[\"loss\"])\n",
    "start = loadded[\"epoch\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
