{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Model,DataSet\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from torchmetrics import Accuracy,F1Score\n",
    "from torchmetrics.classification import BinaryAccuracy\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from zemberek import TurkishTokenizer\n",
    "from torchnlp.encoders.text import StaticTokenizerEncoder, stack_and_pad_tensors, pad_tensor\n",
    "import sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"ytu-ce-cosmos/turkish-gpt2\")\n",
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexingError",
     "evalue": "Too many indexers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m df_train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/musasina/projects/teknofest/msnet/datasets/train_final.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m split \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(df_train)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m80\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m100\u001b[39m\n\u001b[0;32m----> 3\u001b[0m df_train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/teknofest/lib/python3.11/site-packages/pandas/core/indexing.py:1184\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[0;32m-> 1184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1186\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/teknofest/lib/python3.11/site-packages/pandas/core/indexing.py:1690\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1689\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_getitem_tuple\u001b[39m(\u001b[38;5;28mself\u001b[39m, tup: \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m-> 1690\u001b[0m     tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_tuple_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1691\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m suppress(IndexingError):\n\u001b[1;32m   1692\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_lowerdim(tup)\n",
      "File \u001b[0;32m~/anaconda3/envs/teknofest/lib/python3.11/site-packages/pandas/core/indexing.py:962\u001b[0m, in \u001b[0;36m_LocationIndexer._validate_tuple_indexer\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_tuple_indexer\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m:\n\u001b[1;32m    959\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;124;03m    Check the key for valid keys across my indexer.\u001b[39;00m\n\u001b[1;32m    961\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 962\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_key_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    963\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_ellipsis(key)\n\u001b[1;32m    964\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(key):\n",
      "File \u001b[0;32m~/anaconda3/envs/teknofest/lib/python3.11/site-packages/pandas/core/indexing.py:1001\u001b[0m, in \u001b[0;36m_LocationIndexer._validate_key_length\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    999\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m IndexingError(_one_ellipsis_message)\n\u001b[1;32m   1000\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key_length(key)\n\u001b[0;32m-> 1001\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IndexingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToo many indexers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m key\n",
      "\u001b[0;31mIndexingError\u001b[0m: Too many indexers"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"/home/musasina/projects/teknofest/msnet/datasets/train_final.csv\")\n",
    "split = len(df_train)*80/100\n",
    "df_train = df_train.iloc[:split,:]\n",
    "df_train[\"text\"] = df_train[\"text\"].convert_dtypes(convert_string=True).iloc[:split]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(examples):\n",
    "    model_inputs = tokenizer(examples, max_length=128,padding=\"max_length\",truncation=True,return_tensors=\"pt\")\n",
    "    return np.array(model_inputs[\"input_ids\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = df_train[\"text\"].map(preprocess).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def convert_to_list(repr:str):\n",
    "    results = []\n",
    "    digits = set(string.digits)\n",
    "    for letter in repr:\n",
    "        if letter in digits:\n",
    "            results.append(int(letter))\n",
    "    return list(reversed(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"labels\"] = df_train[\"labels\"].map(convert_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(df_train[\"labels\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_count = (labels==0).sum()\n",
    "notr_count = (labels==1).sum()\n",
    "negative_count = (labels==2).sum()\n",
    "positive_count = (labels==3).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_labels = []\n",
    "labels = np.array(df_train[\"labels\"].to_list())\n",
    "for row in labels:\n",
    "    encoded_labels.append(np.eye(4)[row])\n",
    "encoded_labels = np.array(encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = torch.Tensor(np.array(encoded_text))\n",
    "#factorized = pd.factorize(df_train[\"label\"])\n",
    "train_label = torch.as_tensor(encoded_labels,dtype=torch.long,device=\"cuda\")\n",
    "train_text = train_text.type(dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"/home/musasina/projects/teknofest/msnet/datasets/train_final.csv\")\n",
    "df_test = df_test.iloc[:split,:]\n",
    "df_test[\"text\"] = df_test[\"text\"].convert_dtypes(convert_string=True).iloc[split:,:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(examples):\n",
    "    model_inputs = tokenizer(examples, max_length=128,padding=\"max_length\",truncation=True,return_tensors=\"pt\")\n",
    "    return np.array(model_inputs[\"input_ids\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = df_test[\"text\"].map(preprocess).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def convert_to_list(repr:str):\n",
    "    results = []\n",
    "    digits = set(string.digits)\n",
    "    for letter in repr:\n",
    "        if letter in digits:\n",
    "            results.append(int(letter))\n",
    "    return list(reversed(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"labels\"] = df_test[\"labels\"].map(convert_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(df_test[\"labels\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_labels = []\n",
    "labels = np.array(df_test[\"labels\"].to_list())\n",
    "for row in labels:\n",
    "    encoded_labels.append(np.eye(4)[row])\n",
    "encoded_labels = np.array(encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = torch.Tensor(np.array(encoded_text))\n",
    "#factorized = pd.factorize(df_train[\"label\"])\n",
    "test_label = torch.as_tensor(encoded_labels,dtype=torch.long,device=\"cuda\")\n",
    "test_text = test_text.type(dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                                            Param #\n",
       "==========================================================================================\n",
       "Model                                                             --\n",
       "├─MFP: 1-1                                                        --\n",
       "│    └─LeakyReLU: 2-1                                             --\n",
       "│    └─ReLU: 2-2                                                  --\n",
       "│    └─Sigmoid: 2-3                                               --\n",
       "│    └─Tanh: 2-4                                                  --\n",
       "│    └─Mish: 2-5                                                  --\n",
       "│    └─SiLU: 2-6                                                  --\n",
       "│    └─SELU: 2-7                                                  --\n",
       "│    └─ELU: 2-8                                                   --\n",
       "│    └─GELU: 2-9                                                  --\n",
       "│    └─Softplus: 2-10                                             --\n",
       "│    └─Linear: 2-11                                               590,592\n",
       "│    └─Linear: 2-12                                               590,592\n",
       "│    └─Linear: 2-13                                               590,592\n",
       "│    └─Linear: 2-14                                               590,592\n",
       "│    └─Linear: 2-15                                               590,592\n",
       "│    └─Linear: 2-16                                               590,592\n",
       "│    └─Linear: 2-17                                               590,592\n",
       "│    └─Linear: 2-18                                               590,592\n",
       "│    └─KAN: 2-19                                                  --\n",
       "│    │    └─ModuleList: 3-1                                       42,467,328\n",
       "│    └─Linear: 2-20                                               25,169,920\n",
       "│    └─Linear: 2-21                                               6,292,992\n",
       "│    └─Linear: 2-22                                               6,148\n",
       "│    └─Linear: 2-23                                               4,100\n",
       "│    └─LayerNorm: 2-24                                            1,536\n",
       "│    └─LayerNorm: 2-25                                            12,288\n",
       "│    └─Dropout1d: 2-26                                            --\n",
       "│    └─Softmax: 2-27                                              --\n",
       "├─BertLMHeadModel: 1-2                                            --\n",
       "│    └─BertModel: 2-28                                            --\n",
       "│    │    └─BertEmbeddings: 3-2                                   (24,972,288)\n",
       "│    │    └─BertEncoder: 3-3                                      (85,054,464)\n",
       "│    └─Flatten: 2-29                                              --\n",
       "==========================================================================================\n",
       "Total params: 188,705,800\n",
       "Trainable params: 78,679,048\n",
       "Non-trainable params: 110,026,752\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model().to(\"cuda\")\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DataSet(train_text,train_label)\n",
    "test_dataset = DataSet(test_text,test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=train_dataset,shuffle=True,batch_size=64)\n",
    "test_dataloader = DataLoader(dataset=test_dataset,shuffle=False,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_count = notr_count + negative_count + positive_count + zero_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_weight = 1.0-((zero_count)/all_count)\n",
    "notr_weight = 1.0-((notr_count)/all_count)\n",
    "negative_weight = 1.0-(negative_count/all_count)\n",
    "positive_weight = 1.0-(positive_count/all_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [zero_weight,notr_weight,negative_weight,positive_weight]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5119485294117647, 0.9285075516693164, 0.7827156200317965, 0.7768282988871225]\n"
     ]
    }
   ],
   "source": [
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_scale_factor = np.sum(weights)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimezer = torch.optim.AdamW(model.parameters(),lr=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.LinearLR(optimizer=optimezer,end_factor=1e-8,total_iters=2)\n",
    "loss = torch.nn.CrossEntropyLoss(weight=torch.Tensor(weights)).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = Accuracy(\"multilabel\",num_labels=4).to(\"cuda\")\n",
    "f1 = F1Score(\"multilabel\",num_labels=4).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = SummaryWriter(\"./log\",comment=\"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spell funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 10:31:33,809 - zemberek.morphology.turkish_morphology - INFO\n",
      "Msg: TurkishMorphology instance initialized in 2.0465104579925537\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "from zemberek import (\n",
    "    TurkishSentenceNormalizer,\n",
    "    TurkishSentenceExtractor,\n",
    "    TurkishMorphology,\n",
    "    TurkishSpellChecker,\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "morphology = TurkishMorphology.create_with_defaults()\n",
    "normalizer = TurkishSentenceNormalizer(morphology)\n",
    "extractor = TurkishSentenceExtractor()\n",
    "spell_checker = TurkishSpellChecker(morphology)\n",
    "\n",
    "def correct_spells(text: str):\n",
    "\n",
    "    words = text.split(\" \")\n",
    "    for i, word in enumerate(words):\n",
    "        try:\n",
    "            words[i] = spell_checker.suggest_for_word(word)[0]\n",
    "        except BaseException:\n",
    "            continue\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_long_text(paragraph: str) -> str:\n",
    "    result = []\n",
    "    for sentence in paragraph:\n",
    "        try:\n",
    "            result.append(normalizer.normalize(sentence))\n",
    "        except BaseException:\n",
    "            continue\n",
    "    return \" \".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/musasina/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "stops = set(stopwords.words(\"turkish\"))\n",
    "\n",
    "def clear_stop_words(sentence):\n",
    "    return [word for word in sentence.split(\" \") if word not in stops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zeyrek\n",
    "\n",
    "analyzer = zeyrek.MorphAnalyzer()\n",
    "\n",
    "def lemmatize_sent(text):\n",
    "    result = []\n",
    "    for word in text:\n",
    "        try:\n",
    "            result.append(analyzer.lemmatize(word)[0][1][0])\n",
    "        except BaseException:\n",
    "            result.append(word)\n",
    "    return \" \".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_sentence(text:str):\n",
    "    text = text.casefold()\n",
    "    text = correct_spells(text)\n",
    "    text = normalize_long_text(text)\n",
    "    text = clear_stop_words(text)\n",
    "    text = lemmatize_sent(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff78e664344845b59a252a23bf12d8c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "315cc1134c1b4ff3916a899fee11406c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started testing ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4905a1b1868249c3a48296bd2b05ed55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc ->  0.4607356693021973\n",
      "test f1 ->  0.4607356693021973\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "575ae64ce12644d5a0b9656c7637d998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started testing ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "537f09db87cd4ad087749f054dc059a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc ->  0.4607356693021973\n",
      "test f1 ->  0.4607356693021973\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68eeefdc53f449838cb089823fca2c14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started testing ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a792f7bcd0394ff599af4983f05afaf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,(x,y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(test_dataloader)):\n\u001b[1;32m     38\u001b[0m     y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m result,inner_y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results,y):\n\u001b[1;32m     41\u001b[0m         results_acc\u001b[38;5;241m.\u001b[39mappend(acc(result,inner_y)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/anaconda3/envs/teknofest/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/teknofest/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/teknofest/msnet/model.py:222\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, input_ids)\u001b[0m\n\u001b[1;32m    220\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m    221\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(input_ids)\u001b[38;5;241m.\u001b[39mlogits\n\u001b[0;32m--> 222\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmfp\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/anaconda3/envs/teknofest/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/teknofest/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/teknofest/msnet/model.py:182\u001b[0m, in \u001b[0;36mMFP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    180\u001b[0m x_final \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_2(x_final)\n\u001b[1;32m    181\u001b[0m x_final \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39melu(x_final)\n\u001b[0;32m--> 182\u001b[0m x_final \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_final\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m x_final \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_final_1(x_final)\n\u001b[1;32m    184\u001b[0m x_final \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgelu(x_final)\n",
      "File \u001b[0;32m~/anaconda3/envs/teknofest/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/teknofest/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/teknofest/msnet/kan.py:285\u001b[0m, in \u001b[0;36mKAN.forward\u001b[0;34m(self, x, update_grid)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m update_grid:\n\u001b[1;32m    284\u001b[0m         layer\u001b[38;5;241m.\u001b[39mupdate_grid(x)\n\u001b[0;32m--> 285\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/envs/teknofest/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/teknofest/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/teknofest/msnet/kan.py:167\u001b[0m, in \u001b[0;36mKANLinear.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    163\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_features)\n\u001b[1;32m    165\u001b[0m base_output \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_activation(x), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_weight)\n\u001b[1;32m    166\u001b[0m spline_output \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mlinear(\n\u001b[0;32m--> 167\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mb_splines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaled_spline_weight\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_features, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m    169\u001b[0m )\n\u001b[1;32m    170\u001b[0m output \u001b[38;5;241m=\u001b[39m base_output \u001b[38;5;241m+\u001b[39m spline_output\n\u001b[1;32m    172\u001b[0m output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m*\u001b[39moriginal_shape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_features)\n",
      "File \u001b[0;32m~/projects/teknofest/msnet/kan.py:103\u001b[0m, in \u001b[0;36mKANLinear.b_splines\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    101\u001b[0m bases \u001b[38;5;241m=\u001b[39m ((x \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m grid[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m&\u001b[39m (x \u001b[38;5;241m<\u001b[39m grid[:, \u001b[38;5;241m1\u001b[39m:]))\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspline_order \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 103\u001b[0m     bases \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    104\u001b[0m         (x \u001b[38;5;241m-\u001b[39m grid[:, : \u001b[38;5;241m-\u001b[39m(k \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)])\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;241m/\u001b[39m (grid[:, k:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m grid[:, : \u001b[38;5;241m-\u001b[39m(k \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)])\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;241m*\u001b[39m bases[:, :, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    107\u001b[0m     ) \u001b[38;5;241m+\u001b[39m (\n\u001b[1;32m    108\u001b[0m         (grid[:, k \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m :] \u001b[38;5;241m-\u001b[39m x)\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;241m/\u001b[39m (grid[:, k \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m :] \u001b[38;5;241m-\u001b[39m grid[:, \u001b[38;5;241m1\u001b[39m:(\u001b[38;5;241m-\u001b[39mk)])\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;241m*\u001b[39m bases[:, :, \u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    111\u001b[0m     )\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m bases\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m==\u001b[39m (\n\u001b[1;32m    114\u001b[0m     x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_features,\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrid_size \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspline_order,\n\u001b[1;32m    117\u001b[0m )\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bases\u001b[38;5;241m.\u001b[39mcontiguous()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(0,2)):\n",
    "    \n",
    "    for i,(x,y) in enumerate(tqdm(train_dataloader)):\n",
    "        model.train()\n",
    "        y = y.to(\"cuda\")\n",
    "        final = model(x)\n",
    "        losses = loss(final[0],y[0].float())\n",
    "        for j in range(1,len(y)):\n",
    "            losses.add_(loss(final[j].squeeze(),y[j].float()))\n",
    "        losses.div_(len(y))\n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "            tensorboard.add_scalar(tag=\"loss\",scalar_value=losses.cpu().item(),global_step=(epoch*len(train_dataloader))+i)\n",
    "        model.train()\n",
    "        optimezer.zero_grad()\n",
    "        losses.backward()\n",
    "        #[loss_back.backward(retain_graph=True) for loss_back in losses]\n",
    "        #torch.nn.utils.clip_grad_norm_(model.parameters(),1.0,error_if_nonfinite=True)\n",
    "        optimezer.step()\n",
    "        if (i+1)%200 == 0:\n",
    "            model.eval()\n",
    "            with torch.inference_mode():\n",
    "                text = \"turkcell müşteri hizmetlerinden istediğim verimi aldım\"\n",
    "                tokens = tokenizer([text], max_length=128,padding=\"max_length\",truncation=True,return_tensors=\"pt\")[\"input_ids\"]\n",
    "                print(model(tokens).argmax(dim=2).view(-1))\n",
    "    scheduler.step()\n",
    "    torch.save({\"model_state_dict\":model.state_dict(),\n",
    "            \"optimezer_state_dict\": optimezer.state_dict(),\n",
    "            \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "            \"loss\": loss.state_dict(),\n",
    "            \"epoch\":epoch},\"./model.pth\")\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        results_acc = []\n",
    "        results_f1 = []\n",
    "        print(\"started testing ...\")\n",
    "        for i,(x,y) in enumerate(tqdm(test_dataloader)):\n",
    "            y = y.to(\"cuda\")\n",
    "            results = model(x)\n",
    "            for result,inner_y in zip(results,y):\n",
    "                results_acc.append(acc(result,inner_y).cpu().item())\n",
    "                results_f1.append(f1(result,inner_y).cpu().item())\n",
    "        print(\"test acc -> \", np.mean(results_acc))\n",
    "        print(\"test f1 -> \", np.mean(results_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    text = \"turkcell müşteri hizmetlerinden istediğim verimi aldım\"\n",
    "    tokens = tokenizer([text], max_length=8,padding=\"max_length\",truncation=True,return_tensors=\"pt\")[\"input_ids\"]\n",
    "    print(model(tokens).argmax(dim=2).view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started testing ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "861a1c285f6a42a6a99586a6488042f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc ->  0.27889183438112347\n",
      "test f1 ->  0.40866448055492904\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    results_acc = []\n",
    "    results_f1 = []\n",
    "    print(\"started testing ...\")\n",
    "    for i,(x,y) in enumerate(tqdm(test_dataloader)):\n",
    "        y = y.to(\"cuda\")\n",
    "        results = model(x)\n",
    "        for result,inner_y in zip(results,y):\n",
    "            results_acc.append(acc(result,inner_y).cpu().item())\n",
    "            results_f1.append(f1(result,inner_y).cpu().item())\n",
    "    print(\"test acc -> \", np.mean(results_acc))\n",
    "    print(\"test f1 -> \", np.mean(results_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadded = torch.load(\"./model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(loadded[\"model_state_dict\"])\n",
    "optimezer.load_state_dict(loadded['optimezer_state_dict'])\n",
    "scheduler.load_state_dict(loadded[\"scheduler_state_dict\"])\n",
    "loss.load_state_dict(loadded[\"loss\"])\n",
    "start = loadded[\"epoch\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
