{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer,AutoModelForTokenClassification\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import stanza\n",
    "from model import Model\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(text:str):\n",
    "    import string\n",
    "    for punc in string.punctuation:\n",
    "        text = text.replace(punc,\"\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = remove_punc(\"Fiber 100mb SuperOnline kullanıcısıyım yaklaşık 2 haftadır @Twitch @Kick_Turkey gibi canlı yayın platformlarında 360p yayın izlerken donmalar yaşıyoruz.  Başka hiç bir operatörler bu sorunu yaşamazken ben parasını verip alamadığım hizmeti neden ödeyeyim ? Turkcell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = remove_punc(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_2 import Model as Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "If you want to use `XLMRobertaLMHeadModel` as a standalone, add `is_decoder=True.`\n",
      "/tmp/ipykernel_5819/3229746068.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_2.load_state_dict(torch.load(\"/home/musasina/Desktop/projects/teknofest/msnet/model_2_128.pth\",map_location=torch.device('cpu'))[\"model_state_dict\"])\n",
      "/home/musasina/anaconda3/envs/teknofest/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_2 = Model2()\n",
    "model_2.load_state_dict(torch.load(\"/home/musasina/Desktop/projects/teknofest/msnet/model_2_128.pth\",map_location=torch.device('cpu'))[\"model_state_dict\"])\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/xlm-roberta-base\")# gpt2 denedım bert denedım gpt denedim ama en iyi bu çıktı\n",
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fiber tensor(0)\n",
      "100mb tensor(2)\n",
      "SuperOnline tensor(2)\n",
      "kullanıcısıyım tensor(2)\n",
      "yaklaşık tensor(2)\n",
      "2 tensor(0)\n",
      "haftadır tensor(2)\n",
      "Twitch tensor(0)\n",
      "KickTurkey tensor(0)\n",
      "gibi tensor(2)\n",
      "canlı tensor(2)\n",
      "yayın tensor(2)\n",
      "platformlarında tensor(2)\n",
      "360p tensor(2)\n",
      "yayın tensor(2)\n",
      "izlerken tensor(2)\n",
      "donmalar tensor(2)\n",
      "yaşıyoruz tensor(0)\n",
      "Başka tensor(0)\n",
      "hiç tensor(2)\n",
      "bir tensor(2)\n",
      "operatörler tensor(2)\n",
      "bu tensor(2)\n",
      "sorunu tensor(2)\n",
      "yaşamazken tensor(2)\n",
      "ben tensor(2)\n",
      "parasını tensor(2)\n",
      "verip tensor(2)\n",
      "alamadığım tensor(2)\n",
      "hizmeti tensor(2)\n",
      "neden tensor(2)\n",
      "ödeyeyim tensor(2)\n",
      "Turkcell tensor(2)\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    tokens = tokenizer([text], max_length=128,padding=\"max_length\",truncation=True,return_tensors=\"pt\")[\"input_ids\"]\n",
    "\n",
    "\n",
    "    for t,o in zip(text.split(),model_2(tokens).argmax(dim=2).view(-1)):\n",
    "        print(t,o)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teknofest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
