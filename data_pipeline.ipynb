{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import torch\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_detect = pipeline('ner', model=\"akdeniz27/bert-base-turkish-cased-ner\",aggregation_strategy=\"first\",device=\"cuda\")\n",
    "\n",
    "pipe_generate = pipeline(\"text-generation\", model=\"ai-forever/mGPT\",device=\"cuda\", \n",
    "                return_full_text=True,\n",
    "                repetition_penalty=1.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "splits = {'train': 'train.csv', 'test': 'test.csv'}\n",
    "df = pd.read_csv(\"hf://datasets/winvoker/turkish-sentiment-analysis-dataset/\" + splits[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"dataset\"]==\"wiki\"].convert_dtypes(convert_string=True)\n",
    "df_text = df[\"text\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153364\n"
     ]
    }
   ],
   "source": [
    "print(len(df_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "from msnet.model import DataSet\n",
    "from tqdm.auto import tqdm\n",
    "ds = DataSet(df_text,df_text)\n",
    "dl=torch.utils.data.DataLoader(ds,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153364\n"
     ]
    }
   ],
   "source": [
    "print(len(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "020792ce29844395979fd03684b27123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for i,(text,_) in tqdm(enumerate(dl)):\n",
    "    if (i+1)==25000:\n",
    "        break\n",
    "    r = pipe_generate([*text],top_k=50,top_p=0.9,do_sample=True,min_length=32,truncation=True,temperature=0.3,max_new_tokens=32)\n",
    "\n",
    "    results.append({\"text\":str(r[0][0][\"generated_text\"]).casefold(),\"label\":\"Notr\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleared_results = []\n",
    "for row in results:\n",
    "    row[\"text\"] = \" \".join(row[\"text\"].split())\n",
    "    cleared_results.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(cleared_results).to_csv(\"/home/musasina/projects/teknofest/msnet/datasets/data_notr.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/home/musasina/projects/teknofest/msnet/datasets/countries.csv\")[\"surnames\"].convert_dtypes(convert_string=True).to_list()\n",
    "result = []\n",
    "for row in df:\n",
    "    text = row.split()\n",
    "    for country in text:\n",
    "        result.append(str(country).casefold().strip())\n",
    "\n",
    "pd.DataFrame(data=result,columns=[\"names\"]).to_csv(\"/home/musasina/projects/teknofest/msnet/datasets/countries.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teknofest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
