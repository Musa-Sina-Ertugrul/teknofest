{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from torchmetrics import Accuracy,F1Score\n",
    "from torchmetrics.classification import BinaryAccuracy\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from zemberek import TurkishTokenizer\n",
    "from torchnlp.encoders.text import StaticTokenizerEncoder, stack_and_pad_tensors, pad_tensor\n",
    "import sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-turkish-cased\")\n",
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.utils\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"/home/musasina/projects/teknofest/msnet/datasets/train_final_2_128.csv\")\n",
    "df_notr = df[df[\"sentiment\"]==1]\n",
    "df_pos = df[df[\"sentiment\"]==3]\n",
    "df_neg = df[df[\"sentiment\"]==2]\n",
    "df = sklearn.utils.shuffle(pd.concat((df_neg,df_notr,df_pos),ignore_index=True),random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27051\n",
      "231808\n",
      "294423\n"
     ]
    }
   ],
   "source": [
    "print(len(df_notr))\n",
    "print(len(df_pos))\n",
    "print(len(df_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    text = \"turkcell müşteri hizmetlerinden istediğim verimi aldım fakat daha iyi olabilirdi memnun kalmadım ama kick ten memnun kaldim bana yardımcı oldular\"\n",
    "    tokens = tokenizer([text], max_length=32,padding=\"max_length\",truncation=True,return_tensors=\"pt\")[\"input_ids\"]\n",
    "    print(model(tokens).argmax(dim=2).view(-1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teknofest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
